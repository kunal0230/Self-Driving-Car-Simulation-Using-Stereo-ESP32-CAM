import numpy as np
import cv2
import requests
import time
import matplotlib.pyplot as plt
from cv2 import ximgproc

# A* dependencies
from pathfinding.core.diagonal_movement import DiagonalMovement
from pathfinding.core.grid import Grid
from pathfinding.finder.a_star import AStarFinder

# ============ USER CONFIG ==============
# ============ USER CONFIG ==============
LEFT_CAM_IP  = "192.168.0.178"
RIGHT_CAM_IP = "192.168.0.159"
FRAME_WIDTH  = 640  # Must match your calibration resolution
FRAME_HEIGHT = 480

# Hard-coded row index for the "floor plane" in the disparity map 
# (this is scene-specific; you may prefer a plane-fitting approach)
yfloor = 340  

# Number of frames to process in a loop
NUM_FRAMES = 100

# Stereo SGBM parameters
minDisp = 0
nDisp  = 96   # must be multiple of 16
bSize  = 9
P1 = 8*3*bSize**2
P2 = 32*3*bSize**2
modeSgbm = cv2.StereoSGBM_MODE_SGBM
pfCap = 0
sRange = 0

# Weighted Least Squares parameters
lam = 32000
sigma = 2.5
discontinuityRad = 4
# =======================================

import os

# Paths to calibration files (generated by the previous step)
CALIB_DIR = "Calibration_Files"
undistL_path = os.path.join(CALIB_DIR, 'umapL.txt')
rectifL_path = os.path.join(CALIB_DIR, 'rmapL.txt')
undistR_path = os.path.join(CALIB_DIR, 'umapR.txt')
rectifR_path = os.path.join(CALIB_DIR, 'rmapR.txt')
roiL_path    = os.path.join(CALIB_DIR, 'ROIL.txt')
roiR_path    = os.path.join(CALIB_DIR, 'ROIR.txt')
Q_path       = os.path.join(CALIB_DIR, 'Q.txt')
CL_path      = os.path.join(CALIB_DIR, 'CmL.txt')
DL_path      = os.path.join(CALIB_DIR, 'DcL.txt')
RL_path      = os.path.join(CALIB_DIR, 'RectifL.txt')

# Load them
undistL = np.loadtxt(undistL_path, dtype=np.float32)
rectifL = np.loadtxt(rectifL_path, dtype=np.float32)
undistR = np.loadtxt(undistR_path, dtype=np.float32)
rectifR = np.loadtxt(rectifR_path, dtype=np.float32)
roiL    = np.loadtxt(roiL_path, dtype=np.int32)
roiR    = np.loadtxt(roiR_path, dtype=np.int32)
Q       = np.loadtxt(Q_path, dtype=np.float32)
CL      = np.loadtxt(CL_path, dtype=np.float32)
DL      = np.loadtxt(DL_path, dtype=np.float32)
RL      = np.loadtxt(RL_path, dtype=np.float32)

# ============ Functions ================

def fetch_frame(cap):
    """Fetch a single frame from the ESP32-CAM VideoCapture stream."""
    ret, frame = cap.read()
    if ret:
        return frame
    else:
        print("Error fetching frame from stream.")
        return None


def rescaleROI(src, roi):
    """Crop the image to the ROI from stereoRectify (valid region)."""
    x, y, w, h = roi
    dst = src[y:y+h, x:x+w]
    return dst

def computeDisparity(imgL, imgR, params):
    """Compute WLS-filtered disparity and reproject to 3D."""
    (minD, nD, bSz, pfC, sR) = params

    # Convert to gray
    grayL = cv2.cvtColor(imgL, cv2.COLOR_BGR2GRAY)
    grayR = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)

    stereoL = cv2.StereoSGBM_create(
        minDisparity=minD,
        numDisparities=nD,
        blockSize=bSz,
        P1=P1,
        P2=P2,
        speckleRange=sR,
        preFilterCap=pfC,
        mode=modeSgbm
    )
    wls = ximgproc.createDisparityWLSFilter(stereoL)
    stereoR = ximgproc.createRightMatcher(stereoL)

    wls.setLambda(lam)
    wls.setDepthDiscontinuityRadius(discontinuityRad)
    wls.setSigmaColor(sigma)

    # Compute disparity from left and right
    t1 = time.time()
    dispL = stereoL.compute(grayL, grayR)
    dispR = stereoR.compute(grayR, grayL)
    t2 = time.time()
    cost_sgbm = t2 - t1

    # Filter
    dispFiltered = wls.filter(dispL, imgL, None, dispR)
    dispVis = ximgproc.getDisparityVis(dispFiltered)  # for visualization

    # Reproject to 3D
    points3D = cv2.reprojectImageTo3D(dispVis, Q, handleMissingValues=True)

    return dispVis, points3D, cost_sgbm

def findPath(disparityMap, points3d, cost_sgbm, frameId):
    """Build occupancy grid from 3D data, run A*, back-project path."""

    # Unpack 3D
    xx = points3d[:,:,0]
    yy = points3d[:,:,1]
    zz = points3d[:,:,2]

    # Clip to avoid large outliers
    xx = np.clip(xx, -25, 60)
    yy = np.clip(yy, -25, 25)
    zz = np.clip(zz,  0, 100)

    # Floor-based obstacle detection (simple approach)
    # We take a horizontal slice near yfloor
    obs_slice = zz[yfloor-10:yfloor, :]  # might adjust depending on your scene
    # For each column, find the minimum Z in that slice
    obstacles = np.amin(obs_slice, axis=0, keepdims=False)

    # Build an occupancy grid
    # We'll do a simple approach: if 'y' >= obstacles, free space, else occupied
    # but we need to define 'y' as some vertical indexing
    # Here, just do a range in 2D
    y_range = np.mgrid[0:np.amax(obstacles), 0:obs_slice.shape[1]][0,:,:]
    occupancy_grid = np.where(y_range >= obstacles, 0, 1)  # 0 = free, 1 = obstacle

    # Optionally clear near edges if needed
    occupancy_grid[:, :nDisp+60] = 0

    # Find a "farthest free cell"
    # We'll just pick the highest value in occupancy_grid[:,:-90]
    # Then unravel index to get coords
    far_zy, far_zx = np.unravel_index(np.argmax(np.flip(occupancy_grid[:,:-90])), occupancy_grid[:,:-90].shape)
    # Flip X
    far_zx = (zz.shape[1]-91) - far_zx
    far_zy = occupancy_grid.shape[0] - far_zy - 1

    # A* from some center row to that far cell
    xcenter = 305  # you may want to choose your "start" column
    mat_grid = Grid(matrix=occupancy_grid)
    start = mat_grid.node(xcenter, 1)
    end   = mat_grid.node(far_zx, far_zy)

    tA1 = time.time()
    finder = AStarFinder(diagonal_movement=DiagonalMovement.never)
    path, runs = finder.find_path(start, end, mat_grid)
    tA2 = time.time()
    cost_path = tA2 - tA1

    # Convert path to real-world (X,Y,Z)
    coords = np.array([(xp, zp) for xp, zp in path], dtype=np.int32)

    # We'll do a naive approach: 
    # let's create a "vertical range" across the path length
    # This is not exactly correct but let's keep it for demonstration
    length_path = len(path)
    if length_path < 2:
        print("No path found!")
        return [], occupancy_grid, cost_sgbm, cost_path, far_zx, far_zy

    # We'll just index the row from top to bottom
    # or do a geometric spacing
    y_indices = np.linspace(yy.shape[0]-1, yfloor+1, num=length_path, dtype=np.int32)
    y_indices = np.clip(y_indices, 0, yy.shape[0]-1)

    # Build real-world array
    xw = xx[y_indices, coords[:,0]]
    yw = np.linspace(10, 13, num=length_path)  # very naive approach for demonstration
    zw = np.interp(coords[:,1], [0, np.amax(coords[:,1])], [25, nDisp])

    # Combine
    world_points = np.column_stack((xw, yw, zw))

    # Project back to the original left camera
    rvec = np.zeros((3,), dtype=np.float32)  # since we used rectified model, ignoring external rotation
    tvec = np.zeros((3,), dtype=np.float32)
    pr, _ = cv2.projectPoints(world_points, rvec, tvec, CL, DL)
    pr = np.squeeze(pr, 1)
    # px, py
    return (pr, occupancy_grid, cost_sgbm, cost_path, far_zx, far_zy)

def main():
    # Initialize VideoCapture objects for the cameras
    capL = cv2.VideoCapture(f"http://{LEFT_CAM_IP}:81/stream")
    capR = cv2.VideoCapture(f"http://{RIGHT_CAM_IP}:81/stream")

    if not capL.isOpened():
        print(f"Error: Could not open left camera at {LEFT_CAM_IP}")
        return
    if not capR.isOpened():
        print(f"Error: Could not open right camera at {RIGHT_CAM_IP}")
        return

    # Process NUM_FRAMES frames in a loop
    params = [minDisp, nDisp, bSize, pfCap, sRange]
    for frameId in range(NUM_FRAMES):
        # Fetch frames
        imgL = fetch_frame(capL)
        imgR = fetch_frame(capR)

        if imgL is None or imgR is None:
            print("Error: One of the frames is None. Skipping this iteration.")
            continue

        # (Optional) resize to ensure 640x480
        imgL = cv2.resize(imgL, (FRAME_WIDTH, FRAME_HEIGHT))
        imgR = cv2.resize(imgR, (FRAME_WIDTH, FRAME_HEIGHT))

        # Remap (rectify)
        imgL = cv2.remap(imgL, undistL, rectifL, cv2.INTER_LINEAR)
        imgR = cv2.remap(imgR, undistR, rectifR, cv2.INTER_LINEAR)

        # Crop to valid ROI
        imgL = rescaleROI(imgL, roiL)
        imgR = rescaleROI(imgR, roiR)

        dispMap, points3D, cost_sgbm = computeDisparity(imgL, imgR, params)

        # Occupancy + A*
        pr, occupancy_grid, c_sgbm, c_path, far_zx, far_zy = findPath(dispMap, points3D, cost_sgbm, frameId)

        # Visualization
        fig.clf()
        plt.suptitle(f"Frame #{frameId}")

        # Show left image
        ax1 = fig.add_subplot(2,2,1)
        imL_rgb = cv2.cvtColor(imgL, cv2.COLOR_BGR2RGB)
        ax1.imshow(imL_rgb)
        ax1.set_title("Left Camera with Path")
        ax1.set_xlim([0, imgL.shape[1]])
        ax1.set_ylim([imgL.shape[0], 0])

        if len(pr) > 0:
            px = pr[:,0]
            py = pr[:,1]
            # Color points from near->far
            sc = ax1.scatter(px, py, c=np.linspace(0,1,len(px)), cmap='plasma_r', s=30)

        # 3D view
        ax2 = fig.add_subplot(2,2,2, projection='3d')
        ax2.azim = 90
        ax2.elev = 110
        ax2.set_box_aspect((4,3,3))
        xx = points3D[:,:,0]
        yy = points3D[:,:,1]
        zz = points3D[:,:,2]
        ax2.plot_surface(xx[100:yfloor,:], yy[100:yfloor,:], zz[100:yfloor,:],
                         cmap='viridis_r', rcount=25, ccount=25, linewidth=0, antialiased=False)
        ax2.invert_xaxis()
        ax2.invert_zaxis()
        ax2.set_xlabel('Azimuth (X)')
        ax2.set_ylabel('Elevation (Y)')
        ax2.set_zlabel('Depth (Z)')
        ax2.set_title("3D Reconstructed Scene")
        # If we found a path in real-world coords, optionally scatter them:
        # (We used naive 'world_points' in findPath, do it if needed)

        # Disparity
        ax3 = fig.add_subplot(2,2,3)
        ax3.imshow(dispMap, cmap='gray')
        ax3.set_title("WLS-Filtered Disparity Map")

        # Occupancy
        ax4 = fig.add_subplot(2,2,4)
        ax4.imshow(occupancy_grid, origin='lower', interpolation='none', cmap='gray')
        ax4.set_title("Occupancy Grid with A* Path")

        costStats = f"(far_zx, far_zy)=({far_zx},{far_zy})\ncost_sgbm={c_sgbm:.3f}\ncost_path={c_path:.3f}"
        pathStats = f"Grid steps={occupancy_grid.shape}\n"
        fig.text(0.7, 0.05, costStats)
        fig.text(0.85, 0.05, pathStats)

        plt.pause(0.1)

    plt.ioff()
    plt.show()
    
    
     # Release the cameras
    capL.release()
    capR.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
