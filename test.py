import numpy as np
import cv2
import time
import matplotlib.pyplot as plt
from cv2 import ximgproc

# A* dependencies
from pathfinding.core.diagonal_movement import DiagonalMovement
from pathfinding.core.grid import Grid
from pathfinding.finder.a_star import AStarFinder

# ===================== STREAM URLS ======================
# Use these MJPEG streams from your ESP32-CAM firmware
LEFT_CAM_URL  = "http://192.168.0.159:81/stream"  # Stream URL for Left Camera
RIGHT_CAM_URL = "http://192.168.0.178:81/stream"  # Stream URL for Right Camera

# ===================== USER CONFIG ======================
FRAME_WIDTH  = 640  # Must match your stereo calibration resolution
FRAME_HEIGHT = 480

# Hard-coded row index for the "floor plane" in the disparity map
# (this is scene-specific; you may prefer plane-fitting for better results)
yfloor = 340  

# Number of frames to process in a loop
NUM_FRAMES = 100

# Stereo SGBM parameters
minDisp = 0
nDisp  = 96   # must be multiple of 16
bSize  = 9
P1 = 8*3*bSize**2
P2 = 32*3*bSize**2
modeSgbm = cv2.StereoSGBM_MODE_SGBM
pfCap = 0
sRange = 0

# Weighted Least Squares parameters
lam = 32000
sigma = 2.5
discontinuityRad = 4
# ========================================================

import os

# Paths to calibration files (generated by stereo_calibrate.py)
CALIB_DIR = "Calibration_Files"
undistL_path = os.path.join(CALIB_DIR, 'umapL.txt')
rectifL_path = os.path.join(CALIB_DIR, 'rmapL.txt')
undistR_path = os.path.join(CALIB_DIR, 'umapR.txt')
rectifR_path = os.path.join(CALIB_DIR, 'rmapR.txt')
roiL_path    = os.path.join(CALIB_DIR, 'ROIL.txt')
roiR_path    = os.path.join(CALIB_DIR, 'ROIR.txt')
Q_path       = os.path.join(CALIB_DIR, 'Q.txt')
CL_path      = os.path.join(CALIB_DIR, 'CmL.txt')
DL_path      = os.path.join(CALIB_DIR, 'DcL.txt')
RL_path      = os.path.join(CALIB_DIR, 'RectifL.txt')

# Load calibration data
undistL = np.loadtxt(undistL_path, dtype=np.float32)
rectifL = np.loadtxt(rectifL_path, dtype=np.float32)
undistR = np.loadtxt(undistR_path, dtype=np.float32)
rectifR = np.loadtxt(rectifR_path, dtype=np.float32)
roiL    = np.loadtxt(roiL_path,    dtype=np.int32)
roiR    = np.loadtxt(roiR_path,    dtype=np.int32)
Q       = np.loadtxt(Q_path,       dtype=np.float32)
CL      = np.loadtxt(CL_path,      dtype=np.float32)
DL      = np.loadtxt(DL_path,      dtype=np.float32)
RL      = np.loadtxt(RL_path,      dtype=np.float32)

# Create the StereoSGBM and WLS objects at global scope to avoid re-initializing each frame
stereoL = cv2.StereoSGBM_create(
    minDisparity=0,
    numDisparities=96,  # Try increasing to 160 if needed
    blockSize=11,
    P1=8 * 3 * 11**2,
    P2=32 * 3 * 11**2,
    speckleWindowSize=00,
    speckleRange=0,
    preFilterCap=0,
    mode=cv2.StereoSGBM_MODE_SGBM
)

stereoR = ximgproc.createRightMatcher(stereoL)
wls     = ximgproc.createDisparityWLSFilter(stereoL)
wls.setLambda(lam)
wls.setDepthDiscontinuityRadius(discontinuityRad)
wls.setSigmaColor(sigma)


def rescaleROI(src, roi):
    """Crop the image to the ROI from stereoRectify (valid region)."""
    x, y, w, h = roi
    return src[y:y+h, x:x+w]
def adjust_brightness_contrast(image, brightness=75, contrast=40):
    """
    Adjust brightness and contrast of an image.
    Args:
        image (numpy.ndarray): Input image.
        brightness (int): Brightness adjustment value (-255 to 255).
        contrast (int): Contrast adjustment value (-127 to 127).
    Returns:
        numpy.ndarray: Image with adjusted brightness and contrast.
    """
    if brightness != 0:
        shadow = max(0, brightness)
        highlight = min(255, 255 + brightness)
        alpha_b = (highlight - shadow) / 255
        gamma_b = shadow
        image = cv2.addWeighted(image, alpha_b, image, 0, gamma_b)

    if contrast != 0:
        f = 131 * (contrast + 127) / (127 * (131 - contrast))
        alpha_c = f
        gamma_c = 127 * (1 - f)
        image = cv2.addWeighted(image, alpha_c, image, 0, gamma_c)

    return image
# def histogram_equalization(image):
#     """
#     Perform histogram equalization to enhance contrast.
#     Args:
#         image (numpy.ndarray): Input grayscale image.
#     Returns:
#         numpy.ndarray: Contrast-enhanced image.
#     """
#     if len(image.shape) == 3:  # If BGR
#         image_yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)
#         image_yuv[:, :, 0] = cv2.equalizeHist(image_yuv[:, :, 0])  # Equalize Y channel
#         return cv2.cvtColor(image_yuv, cv2.COLOR_YUV2BGR)
#     else:
#         return cv2.equalizeHist(image)  # Grayscale

#         # Usage
#         imgL = histogram_equalization(imgL)
#         imgR = histogram_equalization(imgR)


def computeDisparity(imgL, imgR):
    """Compute WLS-filtered disparity and reproject to 3D."""
    grayL = cv2.cvtColor(imgL, cv2.COLOR_BGR2GRAY)
    grayR = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)

    # Debug prints
    print("grayL.shape =", grayL.shape, "grayL.dtype =", grayL.dtype)
    print("grayR.shape =", grayR.shape, "grayR.dtype =", grayR.dtype)

    # Resize both images to match dimensions
    h, w = min(grayL.shape[0], grayR.shape[0]), min(grayL.shape[1], grayR.shape[1])
    grayL = cv2.resize(grayL, (w, h), interpolation=cv2.INTER_LINEAR)
    grayR = cv2.resize(grayR, (w, h), interpolation=cv2.INTER_LINEAR)

    print("After resizing:")
    print("grayL.shape =", grayL.shape)
    print("grayR.shape =", grayR.shape)

    t1 = time.time()
    dispL = stereoL.compute(grayL, grayR)
    dispR = stereoR.compute(grayR, grayL)
    t2 = time.time()
    cost_sgbm = t2 - t1

    # Filter disparity
    dispFiltered = wls.filter(dispL, imgL, None, dispR)
    dispVis = ximgproc.getDisparityVis(dispFiltered)  # for visualization

    # Reproject to 3D
    points3D = cv2.reprojectImageTo3D(dispVis, Q, handleMissingValues=True)

    return dispVis, points3D, cost_sgbm




def findPath(dispVis, points3d, cost_sgbm, frameId):
    """Build occupancy grid from 3D data, run A*, back-project path, etc."""
    xx = points3d[:,:,0]
    yy = points3d[:,:,1]
    zz = points3d[:,:,2]

    # Clip to avoid large outliers
    xx = np.clip(xx, -25, 60)
    yy = np.clip(yy, -25, 25)
    zz = np.clip(zz,  0, 100)

    # Floor-based obstacle detection
    obs_slice = zz[yfloor-10:yfloor, :]
    obstacles = np.amin(obs_slice, axis=0)
    # Construct a simple occupancy grid
    y_range = np.mgrid[0:np.amax(obstacles), 0:obs_slice.shape[1]][0,:,:]
    occupancy_grid = np.where(y_range >= obstacles, 0, 1)  # 0=free, 1=obstacle

    # Clear near left boundary if needed
    occupancy_grid[:, :nDisp+60] = 0

    # Find the farthest free cell
    try:
        far_zy, far_zx = np.unravel_index(np.argmax(np.flip(occupancy_grid[:,:-90])),
                                          occupancy_grid[:,:-90].shape)
        far_zx = (zz.shape[1]-91) - far_zx
        far_zy = occupancy_grid.shape[0] - far_zy - 1
    except:
        # If occupancy_grid is all zeros or something unexpected
        return (None, occupancy_grid, cost_sgbm, 0.0, -1, -1)

    # A* from some center
    xcenter = 305
    mat_grid = Grid(matrix=occupancy_grid)
    start = mat_grid.node(xcenter, 1)
    end   = mat_grid.node(far_zx, far_zy)

    tA1 = time.time()
    finder = AStarFinder(diagonal_movement=DiagonalMovement.never)
    path, runs = finder.find_path(start, end, mat_grid)
    tA2 = time.time()
    cost_path = tA2 - tA1

    if len(path) == 0:
        # No path found
        return (None, occupancy_grid, cost_sgbm, cost_path, far_zx, far_zy)

    coords = np.array([(xp, zp) for xp, zp in path], dtype=np.int32)
    length_path = len(coords)

    # We'll do a naive approach to get "Y" indices for the path
    y_indices = np.linspace(yy.shape[0]-1, yfloor+1, num=length_path, dtype=np.int32)
    y_indices = np.clip(y_indices, 0, yy.shape[0]-1)

    xw = xx[y_indices, coords[:,0]]
    # Just artificially define Y world from 10->13
    yw = np.linspace(10, 13, num=length_path)
    # Z by interpolation
    zw = np.interp(coords[:,1], [0, np.amax(coords[:,1])], [25, nDisp])

    world_points = np.column_stack((xw, yw, zw))

    rvec = np.zeros((3,), dtype=np.float32)
    tvec = np.zeros((3,), dtype=np.float32)
    pr, _ = cv2.projectPoints(world_points, rvec, tvec, CL, DL)
    pr = np.squeeze(pr, 1)

    return (pr, occupancy_grid, cost_sgbm, cost_path, far_zx, far_zy)


def main():
    # Open the two MJPEG streams as VideoCapture
    capL = cv2.VideoCapture(LEFT_CAM_URL)
    capR = cv2.VideoCapture(RIGHT_CAM_URL)

    # Optionally set some properties
    # capL.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)
    # capL.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)
    # capR.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)
    # capR.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)

    plt.ion()
    fig = plt.figure(figsize=(16,9))

    for frameId in range(NUM_FRAMES):
        retL, imgL = capL.read()
        retR, imgR = capR.read()

        if not retL or not retR or imgL is None or imgR is None:
            print("Failed to read from one of the streams. Retrying...")
            time.sleep(0.5)
            continue

        # (Optional) resize to match calibration resolution
        imgL = cv2.resize(imgL, (FRAME_WIDTH, FRAME_HEIGHT))
        imgR = cv2.resize(imgR, (FRAME_WIDTH, FRAME_HEIGHT))

        # Remap (rectify)
        imgL = cv2.remap(imgL, undistL, rectifL, cv2.INTER_LINEAR)
        imgR = cv2.remap(imgR, undistR, rectifR, cv2.INTER_LINEAR)

        # Crop to valid ROI
        imgL = rescaleROI(imgL, roiL)
        imgR = rescaleROI(imgR, roiR)

        # Compute disparity
        dispVis, points3D, cost_sgbm = computeDisparity(imgL, imgR)

        # Find path
        pr, occupancy_grid, _, cost_path, far_zx, far_zy = findPath(dispVis, points3D, cost_sgbm, frameId)

        # Visualization
        fig.clf()
        plt.suptitle(f"Frame #{frameId}")

        # Left camera
        ax1 = fig.add_subplot(2,2,1)
        imL_rgb = cv2.cvtColor(imgL, cv2.COLOR_BGR2RGB)
        ax1.imshow(imL_rgb)
        ax1.set_title("Left Camera with Path")
        ax1.set_xlim([0, imgL.shape[1]])
        ax1.set_ylim([imgL.shape[0], 0])

        # Overlay path if found
        if pr is not None:
            px = pr[:,0]
            py = pr[:,1]
            ax1.scatter(px, py, c=np.linspace(0,1,len(px)), cmap='plasma_r', s=30)

        # 3D Visualization
        ax2 = fig.add_subplot(2,2,2, projection='3d')
        ax2.azim = 90
        ax2.elev = 110
        ax2.set_box_aspect((4,3,3))

        xx = points3D[:,:,0]
        yy = points3D[:,:,1]
        zz = points3D[:,:,2]
        ax2.plot_surface(xx[100:yfloor,:],
                         yy[100:yfloor,:],
                         zz[100:yfloor,:],
                         cmap='viridis_r',
                         rcount=25,
                         ccount=25,
                         linewidth=0,
                         antialiased=False)
        ax2.invert_xaxis()
        ax2.invert_zaxis()
        ax2.set_xlabel('Azimuth (X)')
        ax2.set_ylabel('Elevation (Y)')
        ax2.set_zlabel('Depth (Z)')
        ax2.set_title("3D Reconstructed Scene")

        # Disparity
        ax3 = fig.add_subplot(2,2,3)
        ax3.imshow(dispVis, cmap='gray')
        ax3.set_title("WLS-Filtered Disparity Map")

        # Occupancy
        ax4 = fig.add_subplot(2,2,4)
        ax4.set_title("Occupancy Grid with A* Path")
        if occupancy_grid is not None:
            ax4.imshow(occupancy_grid, origin='lower', interpolation='none', cmap='gray')

        costStats = f"(far_zx, far_zy)=({far_zx},{far_zy})\nSGBM cost={cost_sgbm:.3f}\nPath cost={cost_path:.3f}"
        fig.text(0.7, 0.05, costStats)

        plt.pause(0.1)

    plt.ioff()
    plt.show()

    # Release the captures
    capL.release()
    capR.release()

if __name__ == "__main__":
    main()
